const axios = require('axios');
const { OPENAI_MODEL, headers } = require('./openaiConfig');

async function getAIReply(userText) {
    try {
        const response = await axios.post(
            'https://api.openai.com/v1/chat/completions',
            {
                model: OPENAI_MODEL,
                messages: [
                    {
                        role: 'system',
                        content: 'Sos un asistente amable y profesional de EsTODOMADERA. Respond√© con claridad y simpat√≠a.',
                    },
                    {
                        role: 'user',
                        content: userText,
                    },
                ],
                temperature: 0.7,
                max_tokens: 150,
            },
            { headers }
        );

        const reply = response.data.choices?.[0]?.message?.content;
        return reply?.trim() || 'Lo siento, no entend√≠ tu mensaje. ¬øPod√©s reformularlo?';
    } catch (error) {
        if (error.response?.status === 429) {
            console.warn('üß† OpenAI saturado: l√≠mite de velocidad alcanzado');
            return '‚ö†Ô∏è La IA est√° procesando demasiadas solicitudes. Intent√° en unos segundos.';
        }

        console.error('üß† Error en OpenAI:', error.message);
        return 'Hubo un problema al procesar tu mensaje. Intent√° m√°s tarde.';
    }
}

module.exports = { getAIReply };
